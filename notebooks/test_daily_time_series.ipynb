{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aaf6a9a-ba87-4e56-8e63-414f85017df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now test the daily time series by training it on all of the 2023 data and predicted 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d04a82-6f58-449a-a9e9-2ab79030ac15",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/interim/ts_2023.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load 2023 \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m daily_counts_jfk_2023 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/interim/ts_2023.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Process into a series:\u001b[39;00m\n\u001b[32m      7\u001b[39m daily_counts_jfk_2023.index = daily_counts_jfk_2023[\u001b[33m\"\u001b[39m\u001b[33mpickup_date\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\datasci\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\datasci\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\datasci\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\datasci\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\datasci\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/interim/ts_2023.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load 2023 \n",
    "daily_counts_jfk_2023 = pd.read_csv(\"../data/interim/ts_2023.csv\")\n",
    "\n",
    "# Process into a series:\n",
    "daily_counts_jfk_2023.index = daily_counts_jfk_2023[\"pickup_date\"]\n",
    "daily_counts_jfk_2023 = daily_counts_jfk_2023.drop(\"pickup_date\", axis = 1)\n",
    "daily_counts_jfk_2023.columns = [\"num_taxis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04161cdf-e459-4f09-a3b3-ee75ce6bc4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the 2024 data\n",
    "import glob\n",
    "\n",
    "files_2024 = glob.glob(\"../data/raw/yellow_tripdata_2024*.parquet\")\n",
    "\n",
    "# Load and concatenate all the data into a single data frame:\n",
    "df_2024 = pd.concat((pd.read_parquet(f) for f in files_2024), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ee852-590a-4d44-bb80-cebd0f1cd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343c8de-8b08-427e-b12b-0d44d0fe3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8134e-4ec4-4ece-bc24-9d43b8a9e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ce65c-bfcb-4745-8668-c966f948680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily time series\n",
    "df_2024['pickup_date'] = df_2024['tpep_pickup_datetime'].dt.date\n",
    "\n",
    "# Trips per day\n",
    "daily_counts_2024 = df_2024.groupby('pickup_date').size()\n",
    "\n",
    "# Plot\n",
    "daily_counts_2024.plot(figsize = (12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18973e6d-0e19-4529-bcd7-225db31e8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(daily_counts_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b68d5-4e7d-4952-aebe-a90157e20a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf816f-12b3-4ff2-b0ea-a888830371a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the rows in 2024:\n",
    "df_2024 = df_2024[df_2024['tpep_pickup_datetime'].dt.year == 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63b83b-63d5-4339-95e7-365e42121338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily time series\n",
    "df_2024['pickup_date'] = df_2024['tpep_pickup_datetime'].dt.date\n",
    "\n",
    "# Trips per day\n",
    "daily_counts_2024 = df_2024.groupby('pickup_date').size()\n",
    "\n",
    "# Plot\n",
    "daily_counts_2024.plot(figsize = (12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee289ab-6dc8-41f0-8f9b-066c79ecb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get JFK Airport data\n",
    "df_jfk_2024 = df_2024[df_2024[\"PULocationID\"] == 132].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17cd861-20c4-4298-acd7-dfe8e1422dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jfk_2024.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e96ca7-2736-4673-9b49-52da14e20665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jfk_2024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ab869-33fe-4ac3-b639-a2cf7bb5f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as a .parquet to avoid long reload times in future\n",
    "df_jfk_2024.to_parquet(\"../data/interim/processed_jfk_2024.parquet\")\n",
    "\n",
    "# To reload:\n",
    "# df_jfk_2024 = pd.read_parquet(\"../data/interim/processed_jfk_2024.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27101ac-d844-447a-a813-a3e875d8c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily time series\n",
    "df_jfk_2024['pickup_date'] = df_jfk_2024['tpep_pickup_datetime'].dt.date\n",
    "\n",
    "# Trips per day\n",
    "daily_counts_jfk_2024 = df_jfk_2024.groupby('pickup_date').size()\n",
    "\n",
    "# Plot\n",
    "daily_counts_jfk_2024.plot(figsize = (12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4fb6d9-c9e3-457d-872a-1e68707ef20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jfk_2024['pickup_hour'] = df_jfk_2024['tpep_pickup_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62786d-8d04-497a-8485-e2ddc3663931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum by day by hour\n",
    "by_day_hour_jfk_2024 = df_jfk_2024.groupby(['pickup_date', 'pickup_hour']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15fa56-07b1-4b21-936a-85196022f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(by_day_hour_jfk_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593224fd-4173-48d4-b226-b0aea13e18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hourly counts as a csv\n",
    "by_day_hour_jfk_2024.to_csv(\"../data/interim/ts_hour_2024.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f8a5c-018c-46e8-afc8-4a50f6b05113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593177a2-d4a2-41c4-8130-3b7fbd2ab969",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(daily_counts_jfk_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b88ede-7d5b-4ecf-958e-db1fae25f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series is pd.core.series.Series)  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b327fd-899f-476b-83b8-2443f3128e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the daily counts as a csv\n",
    "daily_counts_jfk_2024.to_csv(\"../data/interim/ts_2024.csv\")\n",
    "\n",
    "# Reload\n",
    "# ts_2024 = pd.read_csv(\"../data/interim/ts_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09a9ed-0b6a-4fb2-9b64-c518739b8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "\n",
    "y = daily_counts_jfk_2023\n",
    "\n",
    "# When forecasting we need the index to have a frequency, for us this is daily\n",
    "y.index = pd.date_range(start=y.index[0], periods=len(y), freq=\"D\")\n",
    "\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index = y.index,\n",
    "    constant = True,   # Dummy feature for bias (y-intercept)\n",
    "    order = 3,         # Polynomial trend (degree 1 = linear)\n",
    "    seasonal = True,    # Adds seasonal dummies\n",
    "    period = 7,        # Weekly seasonality (7-day cycle)\n",
    "    drop = True,       # Drop first column to avoid collinearity\n",
    ")\n",
    "\n",
    "X = dp.in_sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ba1b2-d82d-4fed-a1fa-9c21778ff409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now add in the lag features.\n",
    "# The reason we haven't used all the significant lags is we will need to drop the rows that\n",
    "# contain null values and if we use lag say 49 we will be dropping about 15% of our data\n",
    "\n",
    "for i in [1, 2, 3, 4, 6, 7, 8, 13, 14, 15]:\n",
    "    X[f'y_lag_{i}'] = y.shift(i)\n",
    "\n",
    "# Drop all na rows\n",
    "mask = X.notna().all(axis=1) # keep only rows with no NaNs\n",
    "X = X.loc[mask]\n",
    "y = y.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaee3f7-c885-4a17-ac51-e25788f642a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Fit the model:\n",
    "\n",
    "model = LinearRegression(fit_intercept = False)\n",
    "_ = model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed7a1f-962d-4cb4-8294-48e3c94f86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem with the above is it is technically cheating as we are assuming we know all the lags in advaance, a more realistic exercise is to try and forecast from our 2023 data itself.\n",
    "# Meaning we will have to use our own model predicitons to generate the lags:\n",
    "\n",
    "# Lags we used to train the model\n",
    "lags = [1, 2, 3, 4, 6, 7, 8, 13, 14, 15]\n",
    "def forecast(model, y, lags, steps):\n",
    "    \"\"\"\n",
    "    model  = trained linear regression\n",
    "    y      = pandas Series with historical values\n",
    "    lags   = list of lags used in training (e.g. [1,2,3])\n",
    "    steps  = how many steps ahead to forecast\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = []\n",
    "    y_hist = y.copy()\n",
    "\n",
    "    # Create the deterministic features for the forecast\n",
    "    X_future_det = dp.out_of_sample(steps = steps)\n",
    "\n",
    "    for i in range(steps): \n",
    "\n",
    "        # Get the deterministic row\n",
    "        x_next = X_future_det.iloc[i].copy()\n",
    "        \n",
    "        # Create the lags using historical data\n",
    "        for j in lags:\n",
    "            x_next[f'y_lag_{j}'] = y_hist.iloc[-j]\n",
    "        \n",
    "        # Predict - x_next is a pandas series and needs to be converted to a dataframe for predictions\n",
    "        y_pred = model.predict(pd.DataFrame([x_next], columns = x_next.index))[0]\n",
    "        \n",
    "        # Append prediction to history so it can be used for future lags\n",
    "        new_point = pd.Series(y_pred, index=[X_future_det.index[i]])\n",
    "        y_hist = pd.concat([y_hist, new_point])\n",
    "\n",
    "        # Add prediction to preds series\n",
    "        preds.append(new_point)\n",
    "\n",
    "    # Turn preds into a pandas series\n",
    "    preds = pd.concat(preds)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713777dd-6442-4fe6-b393-59038552572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For forecasting we need y as a Series not a DataFrame:\n",
    "y = y.iloc[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99f1cc-f000-4668-b710-49a9004dbe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forecast(model, y, lags, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641816e-480a-4beb-98f9-f06e92d9cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# Create forecasts, plot and compare to naive baseline\n",
    "def test_forecasts(steps, y_test, y_hist, model):\n",
    "    \"\"\"\n",
    "    steps = array of the step lengths to forecast\n",
    "    y_test = pd.Series of the true future values\n",
    "    y_hist = pd.Series of historical values\n",
    "    model = model to use for forecasting\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute naive predictions\n",
    "    # Today = yesterday\n",
    "    y_pred_naive = y_test.shift(1)\n",
    "    y_pred_naive.iloc[0] = y_hist.iloc[-1]\n",
    "    \n",
    "    print(y_pred_naive) \n",
    "    \n",
    "    for step in steps:\n",
    "        # Forecast\n",
    "        y_fore = forecast(model, y_hist, lags, step)\n",
    "\n",
    "        # Get real values\n",
    "        y_real = y_test.iloc[0:step]\n",
    "\n",
    "        # Compute MAE\n",
    "        mae = mean_absolute_error(y_fore, y_real)\n",
    "        print(f\"MAE: {mae:.2f} for step = {step}\")\n",
    "        \n",
    "        # Compute naive MAE\n",
    "        y_step_pred_naive = y_pred_naive.loc[y_real.index]\n",
    "         \n",
    "        mae_naive = mean_absolute_error(y_real, y_step_pred_naive)\n",
    "        print(f\"Naive MAE: MAE = {mae_naive:.2f}\\n\")\n",
    "\n",
    "        # Plot\n",
    "        ax = y_real.plot(color='0.25', style='.', title=f\"Forecast steps: {step}\")\n",
    "        ax = y_fore.plot(ax=ax, label=\"Forecast\")\n",
    "        ax = y_step_pred_naive.plot(ax = ax, label = \"Naive\")\n",
    "        ax.legend()\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0ce8b-6864-4cb9-83b6-e5baeaf291c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these test forecasts:\n",
    "steps = [1, 2, 3, 7, 14, 28, 30, 60, 180, 365]\n",
    "\n",
    "y_test = daily_counts_jfk_2024\n",
    "\n",
    "test_forecasts(steps, y_test, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1f1d5-553e-4c7f-b90d-cd216eefad3c",
   "metadata": {},
   "source": [
    "Based on the above I now have the suspicision that the deterministic part of the linear regression is causing problems with the forecast. We will now make new model using only lags and redo the forecasting to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f1f71-1132-483d-a8fa-312be1b79319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag design matrix and target series\n",
    "y_lag = daily_counts_jfk_2023.copy()\n",
    "\n",
    "# When forecasting we need the index to have a frequency, for us this is daily\n",
    "y_lag.index = pd.date_range(start=y_lag.index[0], periods=len(y_lag), freq=\"D\")\n",
    "\n",
    "# Create emty lag data frame\n",
    "X_lag = pd.DataFrame(index = y_lag.index)\n",
    "\n",
    "lags = [1, 2, 3, 4, 6, 7, 8, 13, 14, 15]\n",
    "for i in lags:\n",
    "    X_lag[f'y_lag_{i}'] = y.shift(i)\n",
    "\n",
    "# Drop all na rows\n",
    "mask = X_lag.notna().all(axis=1) # keep only rows with no NaNs\n",
    "X_lag = X_lag.loc[mask]\n",
    "y_lag = y_lag.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0429ebf-67d0-46d7-bc01-e30d7bca03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Fit the model:\n",
    "\n",
    "# Linear:\n",
    "model_lag = LinearRegression()\n",
    "model_lag.fit(X_lag, y_lag);\n",
    "\n",
    "# XGBoost:\n",
    "model_xgb = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "model_xgb.fit(X_lag, y_lag);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b9c24-e2bb-42ad-b515-0dd44bfdc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem with the above is it is technically cheating as we are assuming we know all the lags in advaance, a more realistic exercise is to try and forecast from our 2023 data itself.\n",
    "# Meaning we will have to use our own model predicitons to generate the lags:\n",
    "\n",
    "def forecast_lag(model, y, lags, steps):\n",
    "    \"\"\"\n",
    "    model  = trained linear regression\n",
    "    y      = pandas Series with historical values\n",
    "    lags   = list of lags used in training (e.g. [1,2,3])\n",
    "    steps  = how many steps ahead to forecast\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = []\n",
    "    y_hist = y.copy()\n",
    "\n",
    "    for i in range(1, steps + 1): \n",
    "\n",
    "        # Create the next row\n",
    "        next_index = y_hist.index.freq  + y_hist.index[-1]\n",
    "       \n",
    "        next_index = next_index.date() # convert to date\n",
    "        x_next = pd.DataFrame(index = [next_index])\n",
    "        \n",
    "        # Create the lags using historical data\n",
    "        for j in lags:\n",
    "            x_next[f'y_lag_{j}'] = y_hist.iloc[-j]\n",
    "\n",
    "        \n",
    "        # Predict - x_next is a pandas series and needs to be converted to a dataframe for predictions\n",
    "        y_pred = model.predict(x_next)[0]\n",
    "        \n",
    "        # Append prediction to history so it can be used for future lags\n",
    "        new_point = pd.Series(y_pred, index=x_next.index)\n",
    "        y_hist = pd.concat([y_hist, new_point])\n",
    "\n",
    "        # Reset y_hist's index\n",
    "        y_hist.index = pd.date_range(start=y_hist.index[0], periods=len(y_hist), freq=\"D\")\n",
    "\n",
    "\n",
    "        # Add prediction to preds series\n",
    "        preds.append(new_point)\n",
    "\n",
    "    # Turn preds into a pandas series\n",
    "    preds = pd.concat(preds)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8178be-25c5-4ac7-848d-97b369d5f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecasts, plot and compare to naive baseline\n",
    "def test_forecasts_lag(steps, y_test, y_hist, model):\n",
    "    \"\"\"\n",
    "    steps = array of the step lengths to forecast\n",
    "    y_test = pd.Series of the true future values\n",
    "    y_hist = pd.Series of historical values\n",
    "    model = model to use for forecasting\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute naive predictions\n",
    "    # Today = yesterday\n",
    "    y_pred_naive = y_test.shift(1)\n",
    "    y_pred_naive.iloc[0] = y_hist.iloc[-1]\n",
    "    \n",
    "    \n",
    "    for step in steps:\n",
    "        # Forecast\n",
    "        y_fore = forecast_lag(model, y_hist, lags, step)\n",
    "        y_fore.index.name = \"pickup_date\"\n",
    "       \n",
    "        \n",
    "        # Get real values\n",
    "        y_real = y_test.iloc[0:step]\n",
    "\n",
    "        print(y_fore)\n",
    "\n",
    "        # Compute MAE\n",
    "        mae = mean_absolute_error(y_fore, y_real)\n",
    "        print(f\"MAE: {mae:.2f} for step = {step}\")\n",
    "        \n",
    "        # Compute naive MAE\n",
    "        y_step_pred_naive = y_pred_naive.loc[y_real.index] \n",
    "        mae_naive = mean_absolute_error(y_real, y_step_pred_naive)\n",
    "        print(f\"Naive MAE: MAE = {mae_naive:.2f}\\n\")\n",
    "\n",
    "\n",
    "        # Plot\n",
    "        ax = y_real.plot(color='0.25', style='.', title=f\"Forecast steps: {step}\")\n",
    "        ax = y_fore.plot(ax=ax, label=\"Forecast\")\n",
    "        ax = y_step_pred_naive.plot(ax = ax, label = \"Naive\")\n",
    "        ax.legend()\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5faeb-5971-40c9-9aab-fea28256a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these test forecasts:\n",
    "steps = [1, 2, 3, 7, 14, 28, 30, 60, 180, 365]\n",
    "\n",
    "y_test = daily_counts_jfk_2024\n",
    "y_hist = daily_counts_jfk_2023.iloc[:, 0]\n",
    "y_hist.index = pd.date_range(start=y_hist.index[0], periods=len(y_hist), freq=\"D\")\n",
    "\n",
    "test_forecasts_lag(steps, y_test, y_hist, model_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944432e-d154-4d39-902f-8e07079f4fe3",
   "metadata": {},
   "source": [
    "It would now be interesting to do these forecast plots for both XGBoost and the linear model with some variation in the parameters just so we can see who is doing what in terms of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1199ba2-f426-431c-bf46-492e24343436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data for the models:\n",
    "\n",
    "def preprocess_linear(lags, order):\n",
    "    y = daily_counts_jfk_2023\n",
    "\n",
    "    # When forecasting we need the index to have a frequency, for us this is daily\n",
    "    y.index = pd.date_range(start=y.index[0], periods=len(y), freq=\"D\")\n",
    "\n",
    "\n",
    "    dp = DeterministicProcess(\n",
    "        index = y.index,\n",
    "        constant = True,   # Dummy feature for bias (y-intercept)\n",
    "        order = order,         # Polynomial trend (degree 1 = linear)\n",
    "        seasonal = True,    # Adds seasonal dummies\n",
    "        period = 7,        # Weekly seasonality (7-day cycle)\n",
    "        drop = True,       # Drop first column to avoid collinearity\n",
    "    )\n",
    "\n",
    "    X = dp.in_sample()\n",
    "\n",
    "    # We now add in the lag features.\n",
    "    # The reason we haven't used all the significant lags is we will need to drop the rows that\n",
    "    # contain null values and if we use lag say 49 we will be dropping about 15% of our data\n",
    "    \n",
    "    for i in lags:\n",
    "        X[f'y_lag_{i}'] = y.shift(i)\n",
    "    \n",
    "    # Drop all na rows\n",
    "    mask = X.notna().all(axis=1) # keep only rows with no NaNs\n",
    "    X = X.loc[mask]\n",
    "    y = y.loc[mask]\n",
    "\n",
    "    return (X, y, dp)\n",
    "        \n",
    "\n",
    "def preprocess_non_linear(lags):\n",
    "    # Create lag design matrix and target series\n",
    "    y_lag = daily_counts_jfk_2023.copy()\n",
    "    \n",
    "    # When forecasting we need the index to have a frequency, for us this is daily\n",
    "    y_lag.index = pd.date_range(start=y_lag.index[0], periods=len(y_lag), freq=\"D\")\n",
    "    \n",
    "    # Create emty lag data frame\n",
    "    X_lag = pd.DataFrame(index = y_lag.index)\n",
    "    \n",
    "    for i in lags:\n",
    "        X_lag[f'y_lag_{i}'] = y.shift(i)\n",
    "    \n",
    "    # Drop all na rows\n",
    "    mask = X_lag.notna().all(axis=1) # keep only rows with no NaNs\n",
    "    X_lag = X_lag.loc[mask]\n",
    "    y_lag = y_lag.loc[mask]\n",
    "\n",
    "    # Create day of the week feature:\n",
    "    #X_lag[\"day_of_week\"] = X_lag.index.dayofweek\n",
    "    #X_lag[\"is_weekend\"] = (X_lag.index.dayofweek >= 5).astype(int)\n",
    "\n",
    "\n",
    "    return (X_lag, y_lag)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89209037-38e6-4d0f-bc40-f22e88a617f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models:\n",
    "\n",
    "def fit_linear(X,y):\n",
    "    model = LinearRegression(fit_intercept = False)\n",
    "    model.fit(X,y)\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_non_linear(X_lab,y_lag):\n",
    "    # XGBoost:\n",
    "    model_xgb = XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    "    )\n",
    "    model_xgb.fit(X_lag, y_lag);\n",
    "    return model_xgb\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0768a6-99c5-4b7a-8b22-06c60e17f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_linear(model, y, lags, steps, dp):\n",
    "    \"\"\"\n",
    "    model  = trained linear regression\n",
    "    y      = pandas Series with historical values\n",
    "    lags   = list of lags used in training (e.g. [1,2,3])\n",
    "    steps  = how many steps ahead to forecast\n",
    "    dp     = the deterministic process used\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = []\n",
    "    y_hist = y.copy()\n",
    "\n",
    "    # Create the deterministic features for the forecast\n",
    "    X_future_det = dp.out_of_sample(steps = steps)\n",
    "\n",
    "    for i in range(steps): \n",
    "\n",
    "        # Get the deterministic row\n",
    "        x_next = X_future_det.iloc[i].copy()\n",
    "        \n",
    "        # Create the lags using historical data\n",
    "        for j in lags:\n",
    "            x_next[f'y_lag_{j}'] = y_hist.iloc[-j]\n",
    "        \n",
    "        # Predict - x_next is a pandas series and needs to be converted to a dataframe for predictions\n",
    "        y_pred = model.predict(pd.DataFrame([x_next], columns = x_next.index))[0]\n",
    "        \n",
    "        # Append prediction to history so it can be used for future lags\n",
    "        new_point = pd.Series(y_pred, index=[X_future_det.index[i]])\n",
    "        y_hist = pd.concat([y_hist, new_point])\n",
    "\n",
    "        # Add prediction to preds series\n",
    "        preds.append(new_point)\n",
    "\n",
    "    # Turn preds into a pandas series\n",
    "    preds = pd.concat(preds)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754aa27-8fb3-4657-be0e-8368a5adb8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_non_linear(model, y, lags, steps):\n",
    "    \"\"\"\n",
    "    model  = trained linear regression\n",
    "    y      = pandas Series with historical values\n",
    "    lags   = list of lags used in training (e.g. [1,2,3])\n",
    "    steps  = how many steps ahead to forecast\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = []\n",
    "    y_hist = y.copy()\n",
    "\n",
    "    for i in range(1, steps + 1): \n",
    "\n",
    "        # Create the next row\n",
    "        next_index = y_hist.index.freq  + y_hist.index[-1]\n",
    "       \n",
    "        next_index = next_index.date() # convert to date\n",
    "        x_next = pd.DataFrame(index = [next_index])\n",
    "        \n",
    "        # Create the lags using historical data\n",
    "        for j in lags:\n",
    "            x_next[f'y_lag_{j}'] = y_hist.iloc[-j]\n",
    "\n",
    "        # Create day of the week feature:\n",
    "        #x_next[\"day_of_week\"] = next_index.weekday()\n",
    "        #x_next[\"is_weekend\"] = int(next_index.weekday() >= 5)\n",
    "\n",
    "        \n",
    "        # Predict - x_next is a pandas series and needs to be converted to a dataframe for predictions\n",
    "        y_pred = model.predict(x_next)[0]\n",
    "        \n",
    "        # Append prediction to history so it can be used for future lags\n",
    "        new_point = pd.Series(y_pred, index=x_next.index)\n",
    "        y_hist = pd.concat([y_hist, new_point])\n",
    "\n",
    "        # Reset y_hist's index\n",
    "        y_hist.index = pd.date_range(start=y_hist.index[0], periods=len(y_hist), freq=\"D\")\n",
    "\n",
    "\n",
    "        # Add prediction to preds series\n",
    "        preds.append(new_point)\n",
    "\n",
    "    # Turn preds into a pandas series\n",
    "    preds = pd.concat(preds)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31987a08-176d-4d42-b11a-2ae0ad16eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create forecasts, plot and compare to naive baseline, the key difference is we will now pass a list of linear and non linear models for ease of use\n",
    "def test_forecasts_dicts(steps, y_test, y_hist, linear_models, non_linear_models, lags):\n",
    "    \"\"\"\n",
    "    steps = array of the step lengths to forecast\n",
    "    y_test = pd.Series of the true future values\n",
    "    y_hist = pd.Series of historical values\n",
    "    linear_models = dict of linear models\n",
    "    non_linear_models = dict of non linear models\n",
    "    lags = lags used in the models\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute naive predictions\n",
    "    # Today = yesterday\n",
    "    y_pred_naive = y_test.shift(1)\n",
    "    y_pred_naive.iloc[0] = y_hist.iloc[-1]\n",
    "    \n",
    "   \n",
    "    for step in steps:\n",
    "\n",
    "        # Store MAE scores for barplot\n",
    "        mae_scores = {}\n",
    "        \n",
    "        # Get real values\n",
    "        y_real = y_test.iloc[0:step]\n",
    "        \n",
    "        # Plot\n",
    "        ax = y_real.plot(color='0.25', style='.', title=f\"Forecast steps: {step}\")\n",
    "        \n",
    "        # Forecast the linear models:\n",
    "        for name, value in linear_models.items():\n",
    "            model = value[0]\n",
    "            dp = value[1]\n",
    "            \n",
    "            # Get forecast\n",
    "            y_fore_linear = forecast_linear(model, y_hist, lags, step, dp)\n",
    "\n",
    "            # Compute MAE linear\n",
    "            mae_linear = mean_absolute_error(y_fore_linear, y_real)\n",
    "            mae_scores[name] = mae_linear\n",
    "            print(f\"MAE Linear: {mae_linear:.2f} for step = {step}, model = {name}\")\n",
    "\n",
    "            # Add to plot\n",
    "            ax = y_fore_linear.plot(ax = ax, label = name)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Forecast the non linear models:\n",
    "        for name, model in non_linear_models.items():\n",
    "            y_fore_non_linear = forecast_non_linear(model, y_hist, lags, step)\n",
    "            y_fore_non_linear.index.name = \"pickup_date\"\n",
    "\n",
    "            # Compute MAE non linear\n",
    "            mae_non_linear = mean_absolute_error(y_fore_non_linear, y_real)\n",
    "            mae_scores[name] = mae_non_linear\n",
    "            print(f\"MAE Non Linear: {mae_non_linear:.2f} for step = {step}, model = {name}\")\n",
    "\n",
    "            # Add to plot\n",
    "            ax = y_fore_non_linear.plot(ax = ax, label = name)\n",
    "       \n",
    "\n",
    "        \n",
    "       \n",
    "        # Compute naive MAE\n",
    "        y_step_pred_naive = y_pred_naive.loc[y_real.index]\n",
    "         \n",
    "        mae_naive = mean_absolute_error(y_real, y_step_pred_naive)\n",
    "        mae_scores[\"Naive\"] = mae_naive\n",
    "        print(f\"Naive MAE: MAE = {mae_naive:.2f}\\n\")\n",
    "\n",
    "        # Plot forecasts\n",
    "        ax = y_step_pred_naive.plot(ax = ax, label = \"Naive\")\n",
    "        ax.legend()\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.show()\n",
    "\n",
    "        # Plot MAE bar plots:\n",
    "        df_mae = pd.DataFrame(list(mae_scores.items()), columns=[\"Model\", \"MAE\"]) \n",
    "\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.barplot(data=df_mae, x=\"Model\", y=\"MAE\")\n",
    "\n",
    "        plt.title(f\"Model Comparison by MAE, steps = {step}\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b47000-8ca7-43c7-b507-1bf8ebc98c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forecasts\n",
    "def run_forecasts(steps, lags, linear_models, non_linear_models):\n",
    "    y_test = daily_counts_jfk_2024\n",
    "    y_hist = daily_counts_jfk_2023.iloc[:, 0]\n",
    "    y_hist.index = pd.date_range(start=y_hist.index[0], periods=len(y_hist), freq=\"D\")\n",
    "    \n",
    "    test_forecasts_dicts(steps, y_test, y_hist, linear_models, non_linear_models, lags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb737c6a-b4de-481a-8d98-5141d98ab4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models and forecasts\n",
    "steps = [1, 2, 3, 7, 14, 28, 30, 60, 180, 365]\n",
    "lags =  [1, 2, 3, 4, 6, 7, 8, 13, 14, 15]\n",
    "\n",
    "#(X, y, dp) = preprocess_linear(lags)\n",
    "(X_lag, y_lag) = preprocess_non_linear(lags)\n",
    "#linear_model = fit_linear(X,y)\n",
    "non_linear_model = fit_non_linear(X_lag, y_lag)\n",
    "\n",
    "# Create model dicts\n",
    "linear_models = {}\n",
    "\n",
    "for i in [0,1,2,3,4,5]:\n",
    "    (X,y, dp) = preprocess_linear(lags, i)\n",
    "    linear_models[f\"linear_order{i}\"] = (fit_linear(X,y), dp)\n",
    "\n",
    "non_linear_models = {\n",
    "    \"base_non_linear\": non_linear_model\n",
    "}\n",
    "\n",
    "run_forecasts(steps, lags, linear_models, non_linear_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3a33b-b00d-420b-aa1a-ce1127e96476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e93751-4cce-44ff-8607-a2b2149b13b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datasci)",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
